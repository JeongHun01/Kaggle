{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46578f5c-1313-43a1-9670-0a67c2806a1e",
   "metadata": {},
   "source": [
    "## **Fourth Attempt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866a3494-98d2-4a35-aedb-e95e8fec60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('C:/Users/user/Desktop/Study/Kaggle/Titanic/Data_File/train.csv')\n",
    "test_df = pd.read_csv('C:/Users/user/Desktop/Study/Kaggle/Titanic/Data_File/test.csv')\n",
    "sub_df = pd.read_csv('C:/Users/user/Desktop/Study/Kaggle/Titanic/Data_File/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5633cff-d093-4480-b35c-eb6d749aadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that won't be used to make model\n",
    "def delete_features(df):\n",
    "    feature_list = ['PassengerId', 'Ticket', 'Cabin']\n",
    "    df.drop(feature_list, axis = 1, inplace = True)\n",
    "    \n",
    "\n",
    "# Fill Null Value at train data\n",
    "def fill_NaN_train(df):\n",
    "    index_list = df[df['Age'].isna() == 1].index.tolist()\n",
    "    for index in index_list:\n",
    "        Pclass = df[df.index == index]['Pclass'].values.tolist()[0]\n",
    "        if Pclass == 1:\n",
    "            df['Age'][index] = df[df['Pclass'] == 1].loc[:,'Age'].mean()\n",
    "        elif Pclass == 2:\n",
    "            df['Age'][index] = df[df['Pclass'] == 2].loc[:,'Age'].mean()\n",
    "        else:\n",
    "            df['Age'][index] = df[df['Pclass'] == 3].loc[:,'Age'].mean()\n",
    "\n",
    "    df['Embarked'] = df['Embarked'].fillna('C')\n",
    "\n",
    "# Fill Null Value at train test\n",
    "def fill_NaN_test(df):\n",
    "    index_list = df[df['Age'].isna() == 1].index.tolist()\n",
    "    for index in index_list:\n",
    "        Pclass = df[df.index == index]['Pclass'].values.tolist()[0]\n",
    "        if Pclass == 1:\n",
    "            df['Age'][index] = df[df['Pclass'] == 1].loc[:,'Age'].mean()\n",
    "        elif Pclass == 2:\n",
    "            df['Age'][index] = df[df['Pclass'] == 2].loc[:,'Age'].mean()\n",
    "        else:\n",
    "            df['Age'][index] = df[df['Pclass'] == 3].loc[:,'Age'].mean()\n",
    "            \n",
    "    df['Fare'][152] = 28.230436\n",
    "\n",
    "\n",
    "# Extract title from Name\n",
    "def Name_Engineering_train(df):\n",
    "    Title_list = []\n",
    "    for str in df['Name']:\n",
    "        str1 = str.split(', ')[1]\n",
    "        str2 = str1.split('.')[0]\n",
    "        Title_list.append(str2)\n",
    "\n",
    "    \n",
    "    df['Title'] = Title_list\n",
    "    \n",
    "    list = ['Don', 'Rev', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Ms']\n",
    "    for ele in list:\n",
    "        df['Title'] = df['Title'].replace(ele, 'None', inplace = False)\n",
    "    \n",
    "    df.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "# Extract title from Name\n",
    "def Name_Engineering_test(df):\n",
    "    Title_list = []\n",
    "    for str in df['Name']:\n",
    "        str1 = str.split(', ')[1]\n",
    "        str2 = str1.split('.')[0]\n",
    "        Title_list.append(str2)\n",
    "\n",
    "    df['Title'] = Title_list\n",
    "    \n",
    "    list = ['Dona', 'Rev', 'Dr', 'Col', 'Ms']\n",
    "    for ele in list:\n",
    "        df['Title'] = df['Title'].replace(ele, 'None', inplace = False)\n",
    "\n",
    "    df.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "# Transform continous data to 9 selections\n",
    "def Age_Engineering(df):\n",
    "    def Age_Conversion(x):\n",
    "        str = ''\n",
    "        if x < 13:\n",
    "            str = 'Child'\n",
    "        elif x < 35:\n",
    "            str = 'Adult'\n",
    "        elif x < 55:\n",
    "            str = 'Old'\n",
    "        else:\n",
    "            str = 'Senior'\n",
    "        return str\n",
    "\n",
    "    df['Age'] = df['Age'].apply(lambda x : Age_Conversion(x))\n",
    "\n",
    "\n",
    "# Combine SibSp feature and Parch feature to make Family new feature and make 4 selections\n",
    "def Family_Engineering(df):\n",
    "    df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df.drop(['SibSp', 'Parch'], axis = 1, inplace = True)\n",
    "    \n",
    "    def Family_Conversion(x):\n",
    "        str = ''\n",
    "        if x == 0:\n",
    "            str = 'Alone'\n",
    "        elif x <= 3:\n",
    "            str = 'SmallFamily'\n",
    "        elif x <=5:\n",
    "            str = 'MediumFamily'\n",
    "        else:\n",
    "            str = 'BigFamily'\n",
    "\n",
    "        return str\n",
    "\n",
    "    df['Family'] = df['Family'].apply(lambda x : Family_Conversion(x))\n",
    "\n",
    "# Transform continous data to 4 selections\n",
    "def Fare_Engineering(df):\n",
    "    def Fare_Conversion(x):\n",
    "        str = ''\n",
    "        if x < 7.910400:\n",
    "            str = 'level1'\n",
    "        elif x < 14.454200:\n",
    "            str = 'level2'\n",
    "        elif x < 31:\n",
    "            str = 'level3'\n",
    "        else:\n",
    "            str = 'level4'\n",
    "        return str\n",
    "    \n",
    "    df['Fare'] = df['Fare'].apply(lambda x : Fare_Conversion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170239de-b5a0-4986-9349-fff76f04fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Engineering_train(df):\n",
    "    delete_features(df)\n",
    "    fill_NaN_train(df)\n",
    "    Name_Engineering_train(df)\n",
    "    Age_Engineering(df)\n",
    "    Family_Engineering(df)\n",
    "    Fare_Engineering(df)\n",
    "\n",
    "def Feature_Engineering_test(df):\n",
    "    delete_features(df)\n",
    "    fill_NaN_test(df)\n",
    "    Name_Engineering_test(df)\n",
    "    Age_Engineering(df)\n",
    "    Family_Engineering(df)\n",
    "    Fare_Engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b5905a-596f-43aa-9144-083b4ee3c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "Feature_Engineering_train(train_df)\n",
    "Feature_Engineering_test(test_df)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns = ['Title', 'Sex', 'Family', 'Age', 'Fare', 'Embarked'])\n",
    "test_df = pd.get_dummies(test_df, columns = ['Title', 'Sex', 'Family', 'Age', 'Fare', 'Embarked'])                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8b6887-49ae-4cef-8a4a-118a56ce343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = train_df.drop('Survived', axis = 1, inplace = False)\n",
    "Label = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bdba3fb-451b-46c6-9569-65a7be7a6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state = 0)\n",
    "rf_model = RandomForestClassifier(random_state = 0)\n",
    "xgb_model = XGBClassifier(random_state = 0)\n",
    "lgb_model = LGBMClassifier(random_state = 0)\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e94b5e6-f2aa-4cb3-b91f-a520371dbd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 정확도 :  0.8013746783001695\n",
      "Random Forest 정확도 :  0.8193459293201932\n",
      "XGBoost 정확도 :  0.8226978846274559\n",
      "LightGBM 정확도 :  0.8013746783001695\n",
      "Logistic Regression 정확도 :  0.8013746783001695\n"
     ]
    }
   ],
   "source": [
    "# Cheking None-Tuning models performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt_score = cross_val_score(dt_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Decision Tree 정확도 : \", np.mean(dt_score))\n",
    "\n",
    "rf_score = cross_val_score(rf_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Random Forest 정확도 : \", np.mean(rf_score))\n",
    "\n",
    "xgb_score = cross_val_score(xgb_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"XGBoost 정확도 : \", np.mean(xgb_score))\n",
    "\n",
    "lgb_score = cross_val_score(lgb_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"LightGBM 정확도 : \", np.mean(dt_score))\n",
    "\n",
    "lr_score = cross_val_score(lr_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Logistic Regression 정확도 : \", np.mean(dt_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823028f1-fa0e-431d-aec0-03af59602370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter tuning\n",
    "\n",
    "random_seed = [0]\n",
    "\n",
    "# DecisionTree model hyper parameter\n",
    "dt_params = {'max_depth' : [ i for i in range(2,11) ],\n",
    "             'min_samples_split' : [ i for i in range(2,21)],\n",
    "             'min_samples_leaf' : [i for i in range(1,21)],\n",
    "             'criterion' : ['gini', 'entropy'],\n",
    "             'random_state' : random_seed}\n",
    "\n",
    "# RandomForest model hyper parameter\n",
    "rf_params = {'n_estimators' : [50, 100, 125, 150, 175, 200, 250, 300],\n",
    "             'max_depth' : [i for i in range(2,11)],\n",
    "             'criterion' : ['gini', 'entropy'],\n",
    "             'min_samples_leaf' : [ i for i in range(1,21)],\n",
    "             'random_state' : random_seed}\n",
    "\n",
    "# XGBoost model hyper parameter\n",
    "xgb_params = {'n_estimators' : [100, 150, 200, 250, 300, 350, 400],\n",
    "              'max_depth' :[i for i in range(2,11)],\n",
    "              'min_child_weight' : [i for i in range(2,21)],\n",
    "              'colsample_bytree' : [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'subsample' : [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'random_state' : random_seed}\n",
    "\n",
    "# LightGBM model hyper parameter\n",
    "lgb_params = {'n_estimators' : [100, 150, 200, 250, 300, 350, 400],\n",
    "              'max_depth' : [i for i in range(2,11)],\n",
    "              'num_leaves' : [2 * i for i in range(2,61)],\n",
    "              'min_child_samples' : [ i for i in range(1,21)],\n",
    "              'min_child_depth' : [ i for i in range(2,21)],\n",
    "              'colsample_bytree' : [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'subsample' : [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "              'random_state' : random_seed}\n",
    "\n",
    "# Logistic Regression model hyper parameter\n",
    "lr_params = {'penalty' : ['l1', 'l2'],\n",
    "             'C' : [0.01, 0.1, 0.05, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 150, 200],\n",
    "             'solver' : ['lbfgs', 'liblinear']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feecc8d-b166-437d-91a8-c0380d0fe34a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_dt = GridSearchCV(dt_model, param_grid = dt_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_dt.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('Decision Tree', tuned_dt.best_params_, tuned_dt.best_score_))\n",
    "\n",
    "tuned_rf = GridSearchCV(rf_model, param_grid = rf_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_rf.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('Random Forest', tuned_rf.best_params_, tuned_rf.best_score_))\n",
    "\n",
    "tuned_xgb = GridSearchCV(xgb_model, param_grid = xgb_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_xgb.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('XGBoost', tuned_xgb.best_params_, tuned_xgb.best_score_))\n",
    "\n",
    "tuned_lgb = GridSearchCV(lgb_model, param_grid = lgb_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_lgb.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('LightGBM', tuned_lgb.best_params_, tuned_lgb.best_score_))\n",
    "\n",
    "tuned_lr = GridSearchCV(lr_model, param_grid = lr_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_lr.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('Logistic Regression', tuned_lr.best_params_, tuned_lr.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ba715-65ba-461b-b20c-26935d68fc92",
   "metadata": {},
   "source": [
    "Decision Tree 최적 파라미터 : {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 16, 'random_state': 0}, 이때 정확도 : 0.8406063649488418\r\n",
    "Random Forest 최적 파라미터 : {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'n_estimators': 50, 'random_state': 0}, 이때 정확도 : 0.8316301550436256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
