{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46578f5c-1313-43a1-9670-0a67c2806a1e",
   "metadata": {},
   "source": [
    "## **Fourth Attempt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866a3494-98d2-4a35-aedb-e95e8fec60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('C:/Users/user/Desktop/Study/Kaggle/Titanic/Data_File/train.csv')\n",
    "test_df = pd.read_csv('C:/Users/user/Desktop/Study/Kaggle/Titanic/Data_File/test.csv')\n",
    "sub_df = pd.read_csv('C:/Users/user/Desktop/Study/Kaggle/Titanic/Data_File/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5633cff-d093-4480-b35c-eb6d749aadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that won't be used to make model\n",
    "def delete_features(df):\n",
    "    feature_list = ['PassengerId', 'Ticket', 'Cabin']\n",
    "    df.drop(feature_list, axis = 1, inplace = True)\n",
    "    \n",
    "\n",
    "# Fill Null Value at train data\n",
    "def fill_NaN_train(df):\n",
    "    index_list = df[df['Age'].isna() == 1].index.tolist()\n",
    "    for index in index_list:\n",
    "        Pclass = df[df.index == index]['Pclass'].values.tolist()[0]\n",
    "        if Pclass == 1:\n",
    "            df['Age'][index] = df[df['Pclass'] == 1].loc[:,'Age'].mean()\n",
    "        elif Pclass == 2:\n",
    "            df['Age'][index] = df[df['Pclass'] == 2].loc[:,'Age'].mean()\n",
    "        else:\n",
    "            df['Age'][index] = df[df['Pclass'] == 3].loc[:,'Age'].mean()\n",
    "\n",
    "    df['Embarked'] = df['Embarked'].fillna('C')\n",
    "\n",
    "# Fill Null Value at train test\n",
    "def fill_NaN_test(df):\n",
    "    index_list = df[df['Age'].isna() == 1].index.tolist()\n",
    "    for index in index_list:\n",
    "        Pclass = df[df.index == index]['Pclass'].values.tolist()[0]\n",
    "        if Pclass == 1:\n",
    "            df['Age'][index] = df[df['Pclass'] == 1].loc[:,'Age'].mean()\n",
    "        elif Pclass == 2:\n",
    "            df['Age'][index] = df[df['Pclass'] == 2].loc[:,'Age'].mean()\n",
    "        else:\n",
    "            df['Age'][index] = df[df['Pclass'] == 3].loc[:,'Age'].mean()\n",
    "            \n",
    "    df['Fare'][152] = 28.230436\n",
    "\n",
    "\n",
    "# Extract title from Name\n",
    "def Name_Engineering_train(df):\n",
    "    Title_list = []\n",
    "    for str in df['Name']:\n",
    "        str1 = str.split(', ')[1]\n",
    "        str2 = str1.split('.')[0]\n",
    "        Title_list.append(str2)\n",
    "\n",
    "    \n",
    "    df['Title'] = Title_list\n",
    "    \n",
    "    list = ['Don', 'Rev', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Ms']\n",
    "    for ele in list:\n",
    "        df['Title'] = df['Title'].replace(ele, 'None', inplace = False)\n",
    "    \n",
    "    df.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "# Extract title from Name\n",
    "def Name_Engineering_test(df):\n",
    "    Title_list = []\n",
    "    for str in df['Name']:\n",
    "        str1 = str.split(', ')[1]\n",
    "        str2 = str1.split('.')[0]\n",
    "        Title_list.append(str2)\n",
    "\n",
    "    df['Title'] = Title_list\n",
    "    \n",
    "    list = ['Dona', 'Rev', 'Dr', 'Col', 'Ms']\n",
    "    for ele in list:\n",
    "        df['Title'] = df['Title'].replace(ele, 'None', inplace = False)\n",
    "\n",
    "    df.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "# Transform continous data to 9 selections\n",
    "def Age_Engineering(df):\n",
    "    def Age_Conversion(x):\n",
    "        str = ''\n",
    "        if x < 13:\n",
    "            str = 'Child'\n",
    "        elif x < 35:\n",
    "            str = 'Adult'\n",
    "        elif x < 55:\n",
    "            str = 'Old'\n",
    "        else:\n",
    "            str = 'Senior'\n",
    "        return str\n",
    "\n",
    "    df['Age'] = df['Age'].apply(lambda x : Age_Conversion(x))\n",
    "\n",
    "\n",
    "# Combine SibSp feature and Parch feature to make Family new feature and make 4 selections\n",
    "def Family_Engineering(df):\n",
    "    df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df.drop(['SibSp', 'Parch'], axis = 1, inplace = True)\n",
    "    \n",
    "    def Family_Conversion(x):\n",
    "        str = ''\n",
    "        if x == 0:\n",
    "            str = 'Alone'\n",
    "        elif x <= 3:\n",
    "            str = 'SmallFamily'\n",
    "        elif x <=5:\n",
    "            str = 'MediumFamily'\n",
    "        else:\n",
    "            str = 'BigFamily'\n",
    "\n",
    "        return str\n",
    "\n",
    "    df['Family'] = df['Family'].apply(lambda x : Family_Conversion(x))\n",
    "\n",
    "# Transform continous data to 4 selections\n",
    "def Fare_Engineering(df):\n",
    "    def Fare_Conversion(x):\n",
    "        str = ''\n",
    "        if x < 7.910400:\n",
    "            str = 'level1'\n",
    "        elif x < 14.454200:\n",
    "            str = 'level2'\n",
    "        elif x < 31:\n",
    "            str = 'level3'\n",
    "        else:\n",
    "            str = 'level4'\n",
    "        return str\n",
    "    \n",
    "    df['Fare'] = df['Fare'].apply(lambda x : Fare_Conversion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170239de-b5a0-4986-9349-fff76f04fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Engineering_train(df):\n",
    "    delete_features(df)\n",
    "    fill_NaN_train(df)\n",
    "    Name_Engineering_train(df)\n",
    "    Age_Engineering(df)\n",
    "    Family_Engineering(df)\n",
    "    Fare_Engineering(df)\n",
    "\n",
    "def Feature_Engineering_test(df):\n",
    "    delete_features(df)\n",
    "    fill_NaN_test(df)\n",
    "    Name_Engineering_test(df)\n",
    "    Age_Engineering(df)\n",
    "    Family_Engineering(df)\n",
    "    Fare_Engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b5905a-596f-43aa-9144-083b4ee3c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "Feature_Engineering_train(train_df)\n",
    "Feature_Engineering_test(test_df)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns = ['Title', 'Sex', 'Family', 'Age', 'Fare', 'Embarked'])\n",
    "test_df = pd.get_dummies(test_df, columns = ['Title', 'Sex', 'Family', 'Age', 'Fare', 'Embarked'])                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8b6887-49ae-4cef-8a4a-118a56ce343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = train_df.drop('Survived', axis = 1, inplace = False)\n",
    "Label = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bdba3fb-451b-46c6-9569-65a7be7a6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state = 0)\n",
    "rf_model = RandomForestClassifier(random_state = 0)\n",
    "xgb_model = XGBClassifier(random_state = 0)\n",
    "lgb_model = LGBMClassifier(random_state = 0)\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e94b5e6-f2aa-4cb3-b91f-a520371dbd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 정확도 :  0.8013746783001695\n",
      "Random Forest 정확도 :  0.8193459293201932\n",
      "XGBoost 정확도 :  0.8226978846274559\n",
      "LightGBM 정확도 :  0.8013746783001695\n",
      "Logistic Regression 정확도 :  0.8013746783001695\n"
     ]
    }
   ],
   "source": [
    "# Cheking None-Tuning models performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt_score = cross_val_score(dt_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Decision Tree 정확도 : \", np.mean(dt_score))\n",
    "\n",
    "rf_score = cross_val_score(rf_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Random Forest 정확도 : \", np.mean(rf_score))\n",
    "\n",
    "xgb_score = cross_val_score(xgb_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"XGBoost 정확도 : \", np.mean(xgb_score))\n",
    "\n",
    "lgb_score = cross_val_score(lgb_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"LightGBM 정확도 : \", np.mean(dt_score))\n",
    "\n",
    "lr_score = cross_val_score(lr_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Logistic Regression 정확도 : \", np.mean(dt_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823028f1-fa0e-431d-aec0-03af59602370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter tuning\n",
    "\n",
    "random_seed = [0]\n",
    "\n",
    "# DecisionTree model hyper parameter\n",
    "dt_params = {'max_depth' : [ i for i in range(2,11) ],\n",
    "             'min_samples_leaf' : [ 2 * i for i in range(4,11)],\n",
    "             'criterion' : ['gini', 'entropy'],\n",
    "             'random_state' : random_seed}\n",
    "\n",
    "# RandomForest model hyper parameter\n",
    "rf_params = {'n_estimators' : [50, 100, 125, 150, 175, 200, 250, 300],\n",
    "             'max_depth' : [i for i in range(2,11)],\n",
    "             'criterion' : ['gini', 'entropy'],\n",
    "             'min_samples_leaf' : [ 2 * i for i in range(4,11)],\n",
    "             'random_state' : random_seed}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feecc8d-b166-437d-91a8-c0380d0fe34a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_dt = GridSearchCV(dt_model, param_grid = dt_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_dt.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('Decision Tree', tuned_dt.best_params_, tuned_dt.best_score_))\n",
    "\n",
    "tuned_rf = GridSearchCV(rf_model, param_grid = rf_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_rf.fit(drop_Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('Random Forest', tuned_rf.best_params_, tuned_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f57a973-e7da-4807-b30c-05a7fe8189cb",
   "metadata": {},
   "source": [
    "Decision Tree 최적 파라미터 : {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 8, 'random_state': 0}, 이때 정확도 : 0.8260059004456719\n",
    "\r\n",
    "Random Forest 최적 파라미터 : {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 8, 'n_estimators': 150, 'random_state': 0}, 이때 정확도 : 0.8226476680685466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52a237-3d3a-44f6-9d27-dac1de9a22a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc6f8f97-1971-4404-befb-ae3307335d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning XGB with Bayesian hyperopt\n",
    "from hyperopt import hp, STATUS_OK, fmin, tpe, Trials\n",
    "\n",
    "xgb_search_space = {'max_depth' : hp.quniform('max_depth', 2, 6, 1),\n",
    "                    'min_child_weight' : hp.quniform('min_child_weight', 6, 20, 2),\n",
    "                    'colsample_bytree' : hp.uniform('colsample_bytree',0.5, 1),\n",
    "                    'n_estimators' : hp.quniform('n_estimators', 100, 400, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d91b8bb3-975f-4cac-b2fb-dfc4232fdc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB objective function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# caanot use early_stopping_rounds at voting\n",
    "def xgb_objective_func(search_space):\n",
    "    xgb_model = XGBClassifier(eval_metric = 'logloss', random_state = 0,\n",
    "                              max_depth = int(search_space['max_depth']),\n",
    "                              n_estimators = int(search_space['n_estimators']),\n",
    "                              min_child_weight = int(search_space['min_child_weight']),\n",
    "                              colsample_bytree = search_space['colsample_bytree'])\n",
    "    \n",
    "    score_list = cross_val_score(xgb_model, Feature, Label, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "    return {'loss' : -1 * np.mean(score_list), 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7812e87c-c7b5-41e2-b305-6749e4242df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab\n",
    "\n",
    "#trials = Trials()\n",
    "\n",
    "#xgb_best_params = fmin(fn = xgb_objective_func, space = xgb_search_space, algo = tpe.suggest, max_evals = 50, trials = trials)\n",
    "#print(\"XGB 최적 파라미터 : \", xgb_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba53c2-e1ee-4043-9546-f0168a5ab90a",
   "metadata": {},
   "source": [
    "XGB 최적 파라미터 :  {'colsample_bytree': 0.7851036312778981, 'max_depth': 5.0, 'min_child_weight': 20.0, 'n_estimators': 400.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4adb265f-f39d-4eb2-8bcf-57b120a71774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal learning_rate for XGB\n",
    "xgb_lr = {'learning_rate' : hp.uniform('learning_rate', 0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "970b97ff-4c16-4023-830e-6d171b151841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def xgb_lr_func(search_space):\n",
    "    xgb_model = XGBClassifier(random_state = 0,\n",
    "                              max_depth = 5,\n",
    "                              n_estimators = 400,\n",
    "                              min_child_weight = 20,\n",
    "                              colsample_bytree = 0.7851036312778981,\n",
    "                              learning_rate = search_space['learning_rate'])\n",
    "\n",
    "    score_list = cross_val_score(xgb_model, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "\n",
    "    return {'loss' : -1 * np.mean(score_list), 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f19ba6b3-7f12-4fc8-ba64-c9b72d7ebaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [04:03<00:00,  2.44s/trial, best loss: -0.8294143493817087]\n",
      "XGB 최적 learning_rate :  {'learning_rate': 0.2839561561151697}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "xgb_best_lr = fmin(fn = xgb_lr_func, space = xgb_lr, algo = tpe.suggest, max_evals = 100, trials = trials)\n",
    "print(\"XGB 최적 learning_rate : \", xgb_best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "01479e87-96fd-47da-9197-501f0fef0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning LGB with Bayesian hyperopt\n",
    "\n",
    "from hyperopt import hp, STATUS_OK, fmin, tpe, Trials\n",
    "\n",
    "lgb_search_space = {'max_depth' : hp.quniform('max_depth', 2, 5, 1),\n",
    "                    'num_leaves' : hp.quniform('num_leaves', 6, 20, 2),\n",
    "                    'colsample_bytree' : hp.uniform('colsample_bytree',0.5, 1),\n",
    "                    'n_estimators' : hp.quniform('n_estimators', 100, 400, 50),\n",
    "                    'min_child_samples' : hp.quniform('min_child_samples', 10, 30, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62b56b7a-5d1b-4e91-9920-91ae8b2071f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM objective function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def lgb_objective_func(search_space):\n",
    "    lgb_model = LGBMClassifier(random_state = 0,\n",
    "                              max_depth = int(search_space['max_depth']),\n",
    "                              n_estimators = int(search_space['n_estimators']),\n",
    "                              min_child_samples = int(search_space['min_child_samples']),\n",
    "                              colsample_bytree = search_space['colsample_bytree'],\n",
    "                              num_leaves = int(search_space['num_leaves'])\n",
    "                              )\n",
    "\n",
    "    score_list = cross_val_score(lgb_model, Feature, Label , scoring = 'accuracy', cv = 5)\n",
    "\n",
    "    return {'loss' : -1 * np.mean(score_list), 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2e754b6-03e7-4176-9473-bfb925a5a227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [02:23<00:00,  1.43s/trial, best loss: -0.8316427091833534]\n",
      "LGB 최적 파라미터 :  {'colsample_bytree': 0.8557949199571184, 'max_depth': 5.0, 'min_child_samples': 12.0, 'n_estimators': 100.0, 'num_leaves': 18.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "lgb_best_params = fmin(fn = lgb_objective_func, space = lgb_search_space, algo = tpe.suggest, max_evals = 100, trials = trials)\n",
    "print(\"LGB 최적 파라미터 : \", lgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5828b5a6-a72b-42b0-af89-badc6ef6c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal learning_rate for LGBM\n",
    "lgb_lr = {'learning_rate' : hp.uniform('learning_rate', 0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f2ee5fef-b842-4afe-b018-36c6cf57c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def lgb_lr_func(search_space):\n",
    "    lgb_model = LGBMClassifier(\n",
    "                              max_depth = 5,\n",
    "                              n_estimators = 100,\n",
    "                              min_child_samples = 12,\n",
    "                              colsample_bytree = 0.8557949199571184,\n",
    "                              num_leaves = 18,\n",
    "                              learning_rate = search_space['learning_rate']\n",
    "                              )\n",
    "\n",
    "    score_list = cross_val_score(lgb_model, Feature, Label , scoring = 'accuracy', cv = 5)\n",
    "\n",
    "    return {'loss' : -1 * np.mean(score_list), 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8e3ba3c-b3af-4e90-89e4-ffcd9d44ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:52<00:00,  1.12s/trial, best loss: -0.8338899001945892]\n",
      "LGB 최적 learning_rate :  {'learning_rate': 0.11482673793937354}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "lgb_best_lr = fmin(fn = lgb_lr_func, space = lgb_lr, algo = tpe.suggest, max_evals = 100, trials = trials)\n",
    "print(\"LGB 최적 learning_rate : \", lgb_best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5854d95b-c5b2-45b0-ac9d-6a7cf9d0ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model hyper parameter\n",
    "lr_params = {'penalty' : ['l1', 'l2'],\n",
    "             'C' : [0.01, 0.1, 0.05, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 150, 200],\n",
    "             'solver' : ['lbfgs', 'liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e66fde02-744a-4829-ac9f-a0a20c6efb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 최적 파라미터 : {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}, 이때 정확도 : 0.8271608813006088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_lr = GridSearchCV(lr_model, param_grid = lr_params, cv = 5, scoring = 'accuracy', refit = True)\n",
    "tuned_lr.fit(Feature, Label)\n",
    "print(\"{0} 최적 파라미터 : {1}, 이때 정확도 : {2}\".format('Logistic Regression', tuned_lr.best_params_, tuned_lr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3bc4bc82-5c66-4708-ab68-54429e91109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting 정확도 :  0.8271608813006089\n",
      "Soft Voting 정확도 :  0.8249011361496453\n"
     ]
    }
   ],
   "source": [
    "# voting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state = 0, max_depth = 4, min_samples_leaf = 8, criterion = 'gini')\n",
    "rf_model = RandomForestClassifier(random_state = 0, criterion = 'gini', max_depth = 5, min_samples_leaf = 8, n_estimators = 150)\n",
    "xgb_model = XGBClassifier(random_state = 0, max_depth = 5, min_child_weight = 20,\n",
    "                         colsample_bytree = 0.7851036312778981, n_estimators = 400, learning_rate = 0.2839561561151697)\n",
    "lgb_model = LGBMClassifier(random_state = 0, max_depth = 5, num_leaves = 18, min_child_samples = 12,\n",
    "                           colsample_bytree = 0.8557949199571184, n_estimators = 100, learning_rate = 0.11482673793937354)\n",
    "lr_model = LogisticRegression(C = 1, penalty = 'l2', solver = 'lbfgs')\n",
    "\n",
    "# Hard Voting\n",
    "hard_vote = VotingClassifier(estimators = [('DT', dt_model), ('RF', rf_model), ('XGB', xgb_model), ('LGBM', lgb_model), ('LR', lr_model)], \n",
    "                             voting = 'hard')\n",
    "hard_score = cross_val_score(hard_vote, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Hard Voting 정확도 : \", np.mean(hard_score))\n",
    "\n",
    "# Soft Voting\n",
    "soft_vote = VotingClassifier(estimators = [('DT', dt_model), ('RF', rf_model), ('XGB', xgb_model), ('LGBM', lgb_model), ('LR', lr_model)], \n",
    "                             voting = 'soft')\n",
    "soft_score = cross_val_score(soft_vote, Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Soft Voting 정확도 : \", np.mean(soft_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7bd27aec-1100-47b9-8b3a-7023ebc284c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hard_vote.fit(Feature, Label)\n",
    "prediction = hard_vote.predict(test_df)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "\"PassengerId\":sub_df['PassengerId'],\n",
    "\"Survived\": prediction\n",
    "})\n",
    "display(submission)\n",
    "\n",
    "submission.to_csv('hard_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fb7888f-02d0-4e3c-8a7f-e4f196a5e42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soft_vote.fit(Feature, Label)\n",
    "prediction = soft_vote.predict(test_df)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "\"PassengerId\":sub_df['PassengerId'],\n",
    "\"Survived\": prediction\n",
    "})\n",
    "display(submission)\n",
    "\n",
    "submission.to_csv('soft_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445cbd67-4b0d-4ddd-b0da-345587d54e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "Feature_Engineering_train(train_df)\n",
    "Feature_Engineering_test(test_df)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns = ['Title', 'Sex', 'Family', 'Age', 'Fare'])\n",
    "test_df = pd.get_dummies(test_df, columns = ['Title', 'Sex', 'Family', 'Age', 'Fare'])  \n",
    "\n",
    "Feature = train_df.drop('Survived', axis = 1, inplace = False)\n",
    "Label = train_df['Survived']\n",
    "\n",
    "drop_Feature = Feature.drop(['Embarked'], axis = 1, inplace = False)\n",
    "drop_test = test_df.drop(['Embarked'], axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546274a3-c311-4c02-80bb-7dbb243f560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting 정확도 :  0.8282719226664993\n",
      "Soft Voting 정확도 :  0.8260247316552632\n"
     ]
    }
   ],
   "source": [
    "# voting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state = 0, max_depth = 4, min_samples_leaf = 8, criterion = 'gini')\n",
    "rf_model = RandomForestClassifier(random_state = 0, criterion = 'gini', max_depth = 5, min_samples_leaf = 8, n_estimators = 150)\n",
    "xgb_model = XGBClassifier(random_state = 0, max_depth = 5, min_child_weight = 20,\n",
    "                         colsample_bytree = 0.7851036312778981, n_estimators = 400, learning_rate = 0.2839561561151697)\n",
    "lgb_model = LGBMClassifier(random_state = 0, max_depth = 5, num_leaves = 18, min_child_samples = 12,\n",
    "                           colsample_bytree = 0.8557949199571184, n_estimators = 100, learning_rate = 0.11482673793937354)\n",
    "lr_model = LogisticRegression(C = 1, penalty = 'l2', solver = 'lbfgs')\n",
    "\n",
    "# Hard Voting\n",
    "hard_vote = VotingClassifier(estimators = [('DT', dt_model), ('RF', rf_model), ('XGB', xgb_model), ('LGBM', lgb_model), ('LR', lr_model)], \n",
    "                             voting = 'hard')\n",
    "hard_score = cross_val_score(hard_vote, drop_Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Hard Voting 정확도 : \", np.mean(hard_score))\n",
    "\n",
    "# Soft Voting\n",
    "soft_vote = VotingClassifier(estimators = [('DT', dt_model), ('RF', rf_model), ('XGB', xgb_model), ('LGBM', lgb_model), ('LR', lr_model)], \n",
    "                             voting = 'soft')\n",
    "soft_score = cross_val_score(soft_vote, drop_Feature, Label, scoring = 'accuracy', cv = 5)\n",
    "print(\"Soft Voting 정확도 : \", np.mean(soft_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa85791-8c22-4957-a520-79ba2ba82a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hard_vote.fit(drop_Feature, Label)\n",
    "prediction = hard_vote.predict(drop_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "\"PassengerId\":sub_df['PassengerId'],\n",
    "\"Survived\": prediction\n",
    "})\n",
    "display(submission)\n",
    "\n",
    "submission.to_csv('hard_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55978c16-f057-42c0-9e45-2448913412de",
   "metadata": {},
   "source": [
    "과적합을 잡기위해 데이터 분류와 파라미터 튜닝으로 검증 정확도를 약간 포기해보았지만, 큰 의미는 없었음\n",
    "\n",
    "데이터 양이 너무 적어서 어쩔 수 없는 것으로 판단"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
